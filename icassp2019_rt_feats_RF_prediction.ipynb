{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train][Val] score for DurID 1\n",
      "[[0.66121]] [[0.43065]]\n",
      "[[0.00268]] [[0.01191]]\n",
      "[Train][Val] score for DurID 2\n",
      "[[0.70019]] [[0.4963]]\n",
      "[[0.00249]] [[0.01913]]\n",
      "[Train][Val] score for DurID 3\n",
      "[[0.71733]] [[0.52121]]\n",
      "[[0.00339]] [[0.0166]]\n",
      "[Train][Val] score for DurID 4\n",
      "[[0.73996]] [[0.5702]]\n",
      "[[0.00132]] [[0.01109]]\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "\n",
    "# define functions\n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\",1000,\"display.max_columns\",1000):\n",
    "        display(df)\n",
    "def split_vals(a,n): return a[:n].copy(), a[n:].copy()\n",
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train),y_train), rmse(m.predict(X_valid),y_valid),\n",
    "           m.score(X_train,y_train), m.score(X_valid,y_valid)]\n",
    "    if hasattr(m,'oob_score_'): res.append(m.oob_score)\n",
    "    print(res)\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, se\n",
    "\n",
    "# init path\n",
    "data_PATH = \"./icassp2019_data/rt_feats/\"\n",
    "store_PATH = \"./icassp2019_data/rt_feats/\"\n",
    "file_name = 'subject_wise_rt_featsDist_dur_' # initials of RT + FEATs distance data files [25 50 75 100]\n",
    "\n",
    "# load data\n",
    "# file_name index [1 2 3 4] <=> duration [25 50 75 100]\n",
    "durSet = iter([1,2,3,4])\n",
    "for durID in durSet:\n",
    "    df_raw = pd.read_csv(f'{data_PATH}{file_name}{durID}.csv',low_memory=False)\n",
    "    df_raw.RT = np.log10(df_raw.RT)\n",
    "\n",
    "    # view a snapshot of the data\n",
    "    # display(df_raw.head()) # head/tail by default picks up 5 rows\n",
    "\n",
    "    ## Section 1: subjectwise train-val\n",
    "    # get subject IDs\n",
    "    IDs = df_raw.ID.unique()\n",
    "\n",
    "    # init variables\n",
    "    nvals = 10 # 10-fold cross validation\n",
    "    r_score_train = np.zeros((len(IDs),nvals),dtype=float)\n",
    "    r_score_val = np.zeros((len(IDs),nvals),dtype=float)\n",
    "\n",
    "    r_score_mu_train = np.zeros((len(IDs),1),dtype=float)\n",
    "    r_score_mu_val = np.zeros((len(IDs),1),dtype=float)\n",
    "    r_score_ci_train = np.zeros((len(IDs),1),dtype=float)\n",
    "    r_score_ci_val = np.zeros((len(IDs),1),dtype=float)\n",
    "\n",
    "    # init cross validation module\n",
    "    reset_rf_samples()\n",
    "    from sklearn.model_selection import RepeatedKFold \n",
    "    rkf = RepeatedKFold(n_splits=nvals, n_repeats=1, random_state=1)\n",
    "\n",
    "    # loop random forest training and validation for each subject\n",
    "    for i in range(len(IDs)):\n",
    "        # get subject data\n",
    "        df_raw_sub = df_raw.loc[df_raw['ID'] == IDs[i]]\n",
    "        df_raw_sub = df_raw_sub.reset_index()\n",
    "        df_raw_sub = df_raw_sub.drop(['ID','SUB_ID','FILE_ID'],axis=1)\n",
    "        df_trn, y_trn, nas = proc_df(df_raw_sub,'RT')\n",
    "        j = 0\n",
    "        for train_index, valid_index in rkf.split(np.zeros(len(y_trn))):\n",
    "    #         print(\"Train:\", len(train_index), \"Validation:\",len(val_index))\n",
    "            X_train, X_valid = df_trn.loc[train_index].copy(), df_trn.loc[valid_index].copy() \n",
    "            y_train, y_valid = y_trn[train_index], y_trn[valid_index]\n",
    "\n",
    "            m = RandomForestRegressor(n_estimators=40,min_samples_leaf=5,n_jobs=-1)\n",
    "            m.fit(X_train,y_train)\n",
    "\n",
    "            if j == 0:\n",
    "                df_imp = pd.DataFrame(m.feature_importances_,index = X_train.columns,columns\n",
    "                                           = ['importance']).sort_values('importance',ascending=False)\n",
    "                df_imp = df_imp.T\n",
    "                df_imp = df_imp[['F0','LSF','MEL','MFCC','MFCC_D1','MFCC_D2','TEMP','PERCP','SPECT']]\n",
    "            else:\n",
    "                df_imp_1 = pd.DataFrame(m.feature_importances_,index = X_train.columns,columns\n",
    "                                           = ['importance']).sort_values('importance',ascending=False)\n",
    "                df_imp_1 = df_imp_1.T\n",
    "                df_imp_1 = df_imp_1[['F0','LSF','MEL','MFCC','MFCC_D1','MFCC_D2','TEMP','PERCP','SPECT']]\n",
    "\n",
    "                frames = [df_imp, df_imp_1]\n",
    "                df_imp = pd.concat(frames)\n",
    "\n",
    "            r_score_train[i,j] = m.score(X_train,y_train)\n",
    "            r_score_val[i,j] = m.score(X_valid,y_valid)\n",
    "            j = j+1\n",
    "        # summarize feat importance\n",
    "        if i == 0:\n",
    "            df_feat_imp = pd.DataFrame(df_imp.mean(axis=0)).T\n",
    "        else:\n",
    "            df_feat_imp_1 = pd.DataFrame(df_imp.mean(axis=0)).T\n",
    "            frames = [df_feat_imp, df_feat_imp_1]\n",
    "            df_feat_imp = pd.concat(frames)\n",
    "        # store subjectwise train and val mean scores\n",
    "        r_score_mu_train[i], r_score_ci_train[i] = mean_confidence_interval(r_score_train[i,:], confidence=0.95)\n",
    "        r_score_mu_val[i], r_score_ci_val[i] = mean_confidence_interval(r_score_val[i,:], confidence=0.95)\n",
    "\n",
    "    #print(r_score_val)\n",
    "    # plotting\n",
    "    if 0:\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=2, sharex=True)\n",
    "        ax = axs[0]\n",
    "        ax.errorbar(np.arange(1,18), r_score_mu_train, yerr=r_score_ci_train, fmt='-o')\n",
    "        ax.set_title('Training r-square')\n",
    "\n",
    "        ax = axs[1]\n",
    "        ax.errorbar(np.arange(1,18), r_score_mu_val, yerr=r_score_ci_val, fmt='-o')\n",
    "        ax.set_title('Validation r-square')\n",
    "\n",
    "    # store result score as csv\n",
    "    if 0:\n",
    "        np.savetxt(store_PATH+\"randforest_mu_train_subwise_\"+str(durID)+\".csv\", r_score_mu_train, delimiter=\",\")\n",
    "        np.savetxt(store_PATH+\"randforest_mu_val_subwise_\"+str(durID)+\".csv\", r_score_mu_val, delimiter=\",\")\n",
    "        np.savetxt(store_PATH+\"randforest_std_train_subwise_\"+str(durID)+\".csv\", r_score_ci_train, delimiter=\",\")\n",
    "        np.savetxt(store_PATH+\"randforest_std_val_subwise_\"+str(durID)+\".csv\", r_score_ci_val, delimiter=\",\")\n",
    "        df_feat_imp.to_csv(store_PATH+\"randforest_featImportance_subwise_\"+str(durID)+\".csv\", sep='\\t', encoding='utf-8')\n",
    "\n",
    "    ## Section 2: train-val by pooling all subject data\n",
    "    nfeats = 9\n",
    "    nvals = 5\n",
    "    r_score_all_train = np.zeros((1,nvals),dtype=float)\n",
    "    r_score_all_val = np.zeros((1,nvals),dtype=float)\n",
    "    temp = np.zeros((nfeats,nvals),dtype=float)\n",
    "\n",
    "    feats_importance = np.zeros((nfeats,nvals),dtype=float)\n",
    "\n",
    "    r_score_all_mu_train = np.zeros((1,1),dtype=float)\n",
    "    r_score_all_mu_val = np.zeros((1,1),dtype=float)\n",
    "    r_score_all_ci_train = np.zeros((1,1),dtype=float)\n",
    "    r_score_all_ci_val = np.zeros((1,1),dtype=float)\n",
    "\n",
    "    rkf = RepeatedKFold(n_splits=nvals, n_repeats=1, random_state=1)\n",
    "\n",
    "\n",
    "    df_raw_sub = df_raw.drop(['ID','SUB_ID','FILE_ID'],axis=1)\n",
    "    # df_raw_sub = df_raw_sub[['MFCC_D1','MFCC_D2','RT']]\n",
    "    df_trn, y_trn, nas = proc_df(df_raw_sub,'RT')\n",
    "    j = 0\n",
    "    i = 0\n",
    "    for train_index, valid_index in rkf.split(np.zeros(len(y_trn))):\n",
    "    #         print(\"Train:\", len(train_index), \"Validation:\",len(val_index))\n",
    "        X_train, X_valid = df_trn.loc[train_index].copy(), df_trn.loc[valid_index].copy() \n",
    "        y_train, y_valid = y_trn[train_index], y_trn[valid_index]\n",
    "        set_rf_samples(int(len(y_train)*0.5))\n",
    "        m = RandomForestRegressor(n_estimators=40,min_samples_leaf=5, n_jobs=-1)\n",
    "        m.fit(X_train,y_train)\n",
    "\n",
    "        if j == 0:\n",
    "            df_imp = pd.DataFrame(m.feature_importances_,index = X_train.columns,columns\n",
    "                                       = ['importance']).sort_values('importance',ascending=False)\n",
    "            df_imp = df_imp.T\n",
    "            df_imp = df_imp[['F0','LSF','MEL','MFCC','MFCC_D1','MFCC_D2','TEMP','PERCP','SPECT']]\n",
    "        else:\n",
    "            df_imp_1 = pd.DataFrame(m.feature_importances_,index = X_train.columns,columns\n",
    "                                       = ['importance']).sort_values('importance',ascending=False)\n",
    "            df_imp_1 = df_imp_1.T\n",
    "            df_imp_1 = df_imp_1[['F0','LSF','MEL','MFCC','MFCC_D1','MFCC_D2','TEMP','PERCP','SPECT']]\n",
    "\n",
    "            frames = [df_imp, df_imp_1]\n",
    "            df_imp = pd.concat(frames)\n",
    "        r_score_all_train[i,j] = m.score(X_train,y_train)\n",
    "        r_score_all_val[i,j] = m.score(X_valid,y_valid)\n",
    "        j = j+1\n",
    "    df_feat_imp = pd.DataFrame(df_imp.mean(axis=0)).T\n",
    "    r_score_all_mu_train[i], r_score_all_ci_train[i] = mean_confidence_interval(r_score_all_train[i,:], confidence=0.95)\n",
    "    r_score_all_mu_val[i], r_score_all_ci_val[i] = mean_confidence_interval(r_score_all_val[i,:], confidence=0.95)\n",
    "\n",
    "    print('[Train][Val] score for DurID '+str(durID))\n",
    "    print(r_score_all_mu_train, r_score_all_mu_val)\n",
    "    print(r_score_all_ci_train, r_score_all_ci_val)\n",
    "    # display(df_feat_imp)\n",
    "\n",
    "    # store result score as csv\n",
    "    if 0:\n",
    "        np.savetxt(store_PATH+\"randforest_mu_train_subpool_\"+str(durID)+\".csv\", r_score_all_mu_train, delimiter=\",\")\n",
    "        np.savetxt(store_PATH+\"randforest_mu_val_subpool_\"+str(durID)+\".csv\", r_score_all_mu_val, delimiter=\",\")\n",
    "        np.savetxt(store_PATH+\"randforest_std_train_subpool_\"+str(durID)+\".csv\", r_score_all_ci_train, delimiter=\",\")\n",
    "        np.savetxt(store_PATH+\"randforest_std_val_subpool_\"+str(durID)+\".csv\", r_score_all_ci_val, delimiter=\",\")\n",
    "        df_feat_imp.to_csv(store_PATH+\"randforest_featImportance_subpool_\"+str(durID)+\".csv\", sep='\\t', encoding='utf-8')    \n",
    "\n",
    "    # Obtain predicted RT data (Fig. 6 in paper)\n",
    "    predict_train = np.zeros((len(y_train),2),float)\n",
    "    predict_train[:,0] = np.power(10,m.predict(X_train))\n",
    "    predict_train[:,1] = np.power(10,y_train)\n",
    "\n",
    "    predict_val = np.zeros((len(y_valid),2),float)\n",
    "    predict_val[:,0] = np.power(10,m.predict(X_valid))\n",
    "    predict_val[:,1] = np.power(10,y_valid)\n",
    "\n",
    "    # store data\n",
    "    if 0:\n",
    "        np.savetxt(store_PATH+\"randforest_pred_train_subpool.csv\", predict_train, delimiter=\",\")\n",
    "        np.savetxt(store_PATH+\"randforest_pred_val_subpool.csv\", predict_val, delimiter=\",\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
